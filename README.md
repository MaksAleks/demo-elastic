# Elasticsearch

## Основные тезисы

Доки в elasticsearch хранятся в JSON формате в индексе.

Индекс - логическое место хранения доков.

Физически индекс - это группа шардов, разбитых по нодам кластера

Каждый шард хранит какое-то подмножество документов и управляется поисковым
движком [apache lucene](https://lucene.apache.org/)

При создании индекса можно указать, сколько шардов будет в индексе:

```json
{
  "settings": {
    "number_of_shards": 3,
    "number_of_replicas": 1
  }
}
```

Кол-во шардов нельзя изменять после создания индекса, но можно изменять количество реплик

Указывая количество реплик, мы указываем количество реплик для каждого шарда: выше мы указали, что индекс будет состоять
из двух `primary` шардов, и для каждого `primary` шарда будет 1 реплика

Нет смысла хранить реплику на той же ноде кластера, что и `primary` шард, поэтому если при вышеуказанной конфигурации мы
запустим кластер с одной нодой, то на этой ноде будут только 3 `primary` шарда:
![single-node-cluster](./imgs/single-node-cluster.png)

При добавлении второй ноды, на ней будут запущены реплики:
![two-nodes-cluster](./imgs/two-nodes-cluster.png)

При последующем добавлении нод в кластер шарды - `primary` и реплики - будут перераспределяться по нодам для повышения
отказоустойчивости
![three-nodes-cluster](./imgs/three-nodes-cluster.png)

При текущей конфигурации в кластер имеет смысл добавить 6 нод - 3 ноды на каждый `primary` шард и 3 ноды на каждую
реплику.

Повышать кол-во `primary` шардов нельзя. То есть горизонтально масштабировать ресурсы для хранения больше, чем на 3 ноды
не получится. Однако, увеличив кол-во реплик возможно повысить производительность поиска, так как elasticsearch
распаралелливает поисковой запрос по репликам

---
Индекс имеет плоскую структуру - то есть определять явные связи между документами, как в реляционных БД не получится

- Связывать доки можно по айдишникам, например хранить различные доки `Order(orderId, userId)`, `User(userId)` и логику
  связывания
  переложить на плечи приложения
- Либо хранить связь в виде вложенных документов: `OrderId(orderId, user = User(userId))`

Операции над документом в индексе транзакционные.

Транзакционное обновление над несколькими доками не поддерживаются

Документ - это JSON строка - состоит из полей и значений.

Поля в документе можно глобально разделить на два типа:

- точные значения (exact values): используются для фильтрации и уменьшения количества результатов, к которым будет
  применен анализ и скоринг для полнотекстового поиска
- текст (full text): используются для полнотекстового поиска

Для поиска elasticsearch поддерживает inverted index используя apache lucene.

Допустим у нас есть два документа с полем `content`:

- "The quick brown fox jumped over the lazy dog"
- "Quick brown foxes leap over lazy dogs in summer"

Грубо говоря:

- мы разделяем `content` каждого документа на отдельные слова (которые называем term-ы или token-ы),
- сортируем токены
- создаем отображения токена на список документов, где он встречается:

```
Term      Doc_1  Doc_2
-------------------------
Quick   |       |  X
The     |   X   |
brown   |   X   |  X
dog     |   X   |
dogs    |       |  X
fox     |   X   |
foxes   |       |  X
in      |       |  X
jumped  |   X   |
lazy    |   X   |  X
leap    |       |  X
over    |   X   |  X
quick   |   X   |
summer  |       |  X
the     |   X   |
------------------------
```

На самом деле elastcsearch не просто разделяет значения полей на слова и запихивает их в индекс.
Сначала значения полей документа анализируются.

Анализ производится `анализатором (analyzer)`, который состоит из токенизатора `tokenizer` и нули или более
фильтров `filters`

`Tokenizer` используется, чтобы разбить текст на токены.

Токены - состоят из термов `term`

`Term` - это единица поиска текста. Именно термы являются ключами в `inverted index`

Помимо термов токены содержат информацию о позициях термов и их длине

Результатом работы `tokenizer`-а является стрим (stream) токенов

Каждый токен из стрима обрабатывается цепочкой фильтров, например:

- `Lowercase Filter`
- `Synonims Filter`: заменяет один токен на другой на базе правил синонимов (synonym rules)
- `Language stemming filter`: приводит токены к корневой форме, которая
  называется `stem` (`jumping`, `jumped` -> `jump`)

Elasticsearch (и Opensearch) поддерживают
несколько [встроенных анализаторов](https://opensearch.org/docs/latest/analyzers/index/#built-in-analyzers), а
также [множество фильтров](https://opensearch.org/docs/latest/analyzers/token-filters/index/)

Когда в elasticsearch приходит поисковой запрос, сам запрос проходит ту же процедуру анализа, что и проиндексированный
текст, и далее по полученным термам из запроса происходит поиск документов в `inverted index`-е

## Поиск в маркетплейсе

Рассмотрим поиск в elasticsearch на примере маркетплейса.

Что хотят пользователи маркетплейса:

### Функциональные требования для поиска
- Получать ленту товаров на основе выбранной категории
- Искать товары с помощью поисковой строки
- Скроллить ленту с результатами
- Применять фильтры различные фильтры согласно выбранной категории
- Получать as-you-type suggestions
    - Для автокомплита по префиксу введенного текста прямо в поисковой строке.  
      Например, набрав: "декоративная ва" пользователь может желать получить подсказки:
        - "декоративная ваза"  
          Нажав: `tab` заавтокомплитить слово "ваза", и получить следующую подсказку:
        - "декоративная ваза под сухоцветы"
    - Для подсказок в выпадающем списке под поисковой строкой (не только по префиксу)  
      Например, набрав: "декоративная ваза" может жедать получить подсказки
        - "декоративная ваза под сухоцветы"
        - "ваза декоративная керамическая"
        - ...

- Сортрировать результаты:
  - по рейтингу
  - по стоимости
  - по популярности
  - по времени доставки (зависит от расстояния от места положения покупателя до точки, с которой продавец отправляет товар)


Чего пользователи точно не хотят:

- Набрав в поиске "декоративная ваза" они не хотят получить в результате "декоративный горшок"  
  Существительное "ваза" тут играет первостепенную роль. Если ваз на маркетплейсе не нашлось, то другие "декоративные"
  вещи выдавать в качестве результат не нужно.

### Модель данных

Для начала нужно [создать индекс](https://www.elastic.co/guide/en/elasticsearch/guide/master/_creating_an_index.html)

По умолчанию, индекс автоматически создается при попытке добавить туда документ. 

Отключить это можно настройкой: `action.auto_create_index: false`

Подробнее о том, как конфигурить кластер [здесь](https://opensearch.org/docs/2.11/install-and-configure/configuring-opensearch/index/)

Для создания индекса в запросе нужно указать его настройки: `settings` и маппинг полей `mappings`

```http request
PUT /my_index
Content-Type: application/json

{
    "settings": { ... any settings ... },
    "mappings": {
        "type_one": { ... any mappings ... },
        "type_two": { ... any mappings ... },
        ...
    }
}
```

В настройках можно указать, например:
- кол-во шардов в индексе (5 по дефолту)
- кол-во реплик
- ...

Маппинг включает в себя в том числе типы данных полей документа. 
Там можно указать еще другие настройки полей, например, каким анализатором будет анализироваться поле, и другие.
Но пока что остановится на типах данных.

Индекс будет содержать информацию о продуктах, поэтому будет называться `products`

Исходя из [функциональных требовний](#функциональные-требования-для-поиска), продукт будет содержать:
- id
- называние
- описание
- категорию
- цену
- геолокацию
- пользовательский рейтинг
- популярность (для нашего примера просто какое-то число от 0 до 1)

Opensearch поддерживает различные типы данных.
Более подробно о типах данных [можно почитать в документации](https://opensearch.org/docs/latest/field-types/index/)

Сейчас постараемся упростить себе задачу, и рассмотрим только самые базовые типы, необходимые для того, чтоб реализовать базовый поиск.
Идентификатор хранится в метаданных документа, и не объявляется в маппинге.

Для текстовых полей `opensearch` поддерживает:
- `text`: строка, которая проходит через анализатор и разбивается на токены - подходит для полнотекстового поиска
- `keyword`: строка, которая не анализируется, не разделяется на термы, в `inverted index` она входит целиком - подходит для фильтрации

Для чисел ([Numeric](https://opensearch.org/docs/latest/field-types/supported-field-types/numeric/)):
- integer
- long
- float
- double
- ...

Для геологации ([Geographic field types](https://opensearch.org/docs/latest/field-types/supported-field-types/geographic/))
- geo_point
- ...

Используем их для типов полей продукта:

```json
{
  "settings": {
    "number_of_shards": 3,
    "number_of_replicas": 1
  },
  "mappings": {
    "properties": {
      "name": {
        "type": "text"
      },
      "description": {
        "type": "text"
      },
      "category": {
        "type": "keyword"
      },
      "price": {
        "type": "double"
      },
      "rating": {
        "type": "double"
      },
      "popularity": {
        "type": "double"
      },
      "location": {
        "type": "geo_point"
      }
    }
  }
}
```

Можно запустить opensearch кластер в [docker-compose](./docker/docker-compose.yaml) и выполнить запрос:
```http request
PUT http://localhost:9200/products
Content-Type: application/json

{
  "settings": {
    "number_of_shards": 1,
    "number_of_replicas": 3
  },
  "mappings": {
    "properties": {
      "name": {
        "type": "text"
      },
      "description": {
        "type": "text"
      },
      "category": {
        "type": "keyword"
      },
      "price": {
        "type": "double"
      },
      "rating": {
        "type": "double"
      },
      "popularity": {
        "type": "double"
      },
      "location": {
        "type": "geo_point"
      }
    }
  }
}
```

В проекте будем использовать [spring-data-opensearch](https://github.com/opensearch-project/spring-data-opensearch) на базе [spring data elasticsearch](https://docs.spring.io/spring-data/elasticsearch/reference/index.html)

Для отправки запросов в opensearch будем пользоваться `OpenSearchRestTemplate`. Конфигурацию можно посмотреть в [RestClientConfig.java](./src/main/java/ru/max/demo/elastic/RestClientConfig.java)

Метод создания индекса находится в [OpenSearchRestController](./src/main/java/ru/max/demo/elastic/OpenSearchRestController.java)

### Тестовые данные

Чтобы начать искать, организуем тестовые данные.

У нас будут продукты из трех категорий:
- одежда
- декор для дома
- посуда

Тестовые данные размещены в файле [resources/test-data.json](./src/main/resources/test-data.json)

В [OpenSearchRestController](./src/main/java/ru/max/demo/elastic/OpenSearchRestController.java) есть метод `POST /create-test-data`, который вычитывает этот файл и вставляет данные в индекс `products`

### Поиск. Фильтрация

Теперь можно приступать к поиску.

Начнем с первого требования:
- пользователи хотят получать ленту продуктов по выбранной категории

Когда пользователь выбирает категорию "декор для дома", он ожидает увидеть вещи именно из этой категории. Его не интересуют вещи из категории "декор для сада", например. То есть нам **нужно полное соответствие.**

Поисковые запросы в elasticsearch (opensearch) могут выполняться в [двух контекстах](https://opensearch.org/docs/2.11/query-dsl/query-filter-context):
- `filter context`: в этом контексте запрос спрашивает "подходит ли доукмент под этот запрос или нет" и возвращает подходящие документы без вычисления релевантности.
- `query context`: в этом контексте запрос спрашивает "насколько документ подходит под запрос" и возвращает документы отсортированные по релевантности

При фильтрации не выполняется анализ запроса, разбиение его на термы, подсчет релевантности и сортировка результатов.
Поэтому фильтрация происходит намного быстрее, чем поиск.
И поэтому фильтровать имеет смысл только по `exact value` полям.

`The goal of filtering is to reduce the number of documents that have to be examined by the scoring queries.`

Мы сделали поле `category` как раз `exact value` полем - с типом `keyword`

Для точного совпадения используется т.н. [term запрос](https://opensearch.org/docs/latest/query-dsl/term/term/). 

Чтобы запустить этот запрос в `filter context` нужно использовать `filter clause`. Но его мы можем использовать только в [compound queries](https://opensearch.org/docs/2.11/query-dsl/compound/index/). Например `constant_score`, который просто присваивает результатам поиска одинаковое значение релевантности

`GET http://localhost:9200/products/_search`
```json
{
    "query" : {
        "constant_score" : { 
            "filter" : {
                "term" : { 
                    "category" : "декор для дома"
                }
            }
        }
    }
}
```

Разберемся со структурой.

Все поисковые запросы (В том числе на фильтрацию) имеют следующий формат:
```json
{
    "query": "YOUR_QUERY_HERE"
}
```

Например:
1) Для поиска всех документов в индексе используется запрос `match_all: {}`:
```json
{
    "query": {
        "match_all": {}
    }
}
```
2) Для простого полнотекстового поиска по конкретному полю - `match`:
```json
{
    "query": {
        "match": {
          // name - это название поля в документе
          "name": "плед"
        }
    }
}
```

3) А для фильтрации по `exact value` полю - `term` в `filter` контексте (`filter` clause) (обернутый в [compound запрос](https://opensearch.org/docs/2.11/query-dsl/compound/index/)). Например, как было указано выше:
```json
{
    "query" : {
        "constant_score" : { 
            "filter" : {
                "term" : { 
                    "category" : "декор для дома"
                }
            }
        }
    }
}
```

Или:
```json
{
    "query" : {
        "bool" : { 
            "filter" : {
                "term" : { 
                    "category" : "декор для дома"
                }
            }
        }
    }
}
```

4) Вот [список базовых запросов](https://www.elastic.co/guide/en/elasticsearch/guide/master/_most_important_queries.html)

И так, запрос  
`GET http://localhost:9200/products/_search`
```json
{
    "query" : {
        "constant_score" : { 
            "filter" : {
                "term" : { 
                    "category" : "декор для дома"
                }
            }
        }
    }
}
```

отдает продукты из категории "декор для дома".

Эти результаты будут отображаться в ленте на UI, поэтому нужна возможность скролить результаты

Наиболее оптимальный способ - использовать [Point in time search](https://opensearch.org/docs/latest/search-plugins/point-in-time/)

При этом подходе создается PIT (point in time) - фактически snapshot индекса на определенный промежуток времени, задаваемый при его создании:

`POST /products/_search/point_in_time?keep_alive=10m`

В результате возвращается PIT ID, который используется при отправке запросов на поиск. При этом нужно использовать сортировку по какому-то полю по умолчанию, чтобы иметь возможность запрашивать следующую пачку результатов. В нашем случае сортировка по умолчанию будет по популярности товара:

```json
{
  "size": 4,
  "track_total_hits": false,
  "query": {
    "constant_score": {
      "filter": {
        "term": {
          "category": "декор для дома"
        }
      }
    }
  },
  "pit": {
    "id": "the_pit_id",
    "keep_alive": "10m"
  },
  "sort": [
    {
      "popularity": "desc"
    }
  ]
}
```

Мы установили `track_total_hist: false` для увеличения производительности и уменьшения затрат ресурсов во время выполнения запроса, так как если оставить его по дефолту `true`, то opensearch должен будет с каждого шарда запросить все документы, которые подходят под критерий, чтобы посчитать их кол-во. Если же установить в `false`, он запросит только максимум `size` результатов.

В результате вернулся список результатов, в котором последний имел значение:
```json
            {
  "_index": "products",
  "_id": "DoeB8YsBl3JKYKoOAx4P",
  "_score": null,
  "_source": {
    "_class": "ru.max.demo.elastic.model.Product",
    "category": "декор для дома",
    "name": "Шерстяной плед серого цвета",
    "description": "Теплый и мягкий шерстяной плед серого цвета. Идеален для создания уюта в холодные вечера.",
    "price": 3200.0,
    "rating": 4.6,
    "popularity": 0.85,
    "location": {
      "lat": 55.7558,
      "lon": 37.6173
    }
  },
  "sort": [
    0.85
  ]
}
```

В нем параметр `sort` имеет значение `0.85`. 
Это значение мы будем использовать для получения следующей страницы.

Чтобы получить следующую страницу, нужно указать [search_after](https://opensearch.org/docs/latest/search-plugins/searching-data/paginate/#the-search_after-parameter) параметр. Он используется и сам по себе, и [вместе с PIT поиском](https://opensearch.org/docs/latest/search-plugins/point-in-time/#pagination-with-pit-and-search_after)

```json
{
  "size": 3,
  "track_total_hits": false,
  "query": {
    "constant_score": {
      "filter": {
        "term": {
          "category": "декор для дома"
        }
      }
    }
  },
  "pit": {
    "id": "the_pit_id",
    "keep_alive": "10m"
  },
  "sort": [
    {
      "popularity": "desc"
    }
  ],
  "search_after": [0.85]
}
```

И так пока не вернется пустая страница.

Я добавил ручку `/index/filter/{index}` в [OpenSearchRestController](./src/main/java/ru/max/demo/elastic/OpenSearchRestController.java)
для фильтрации с возможностью скролить результат через PIT запрос.





